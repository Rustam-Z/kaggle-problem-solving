{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.6 64-bit ('tf': conda)"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.6","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"interpreter":{"hash":"4ea0e157563bacde0b7fd8dc93db6051c9678d5eadbd4117abf1a4cecbc8cd1a"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## Project Planning\n","* **Goal:** predict if a passenger survived (1 / 0) \n","* **Metrics:** accuracy\n","* **TODO**:\n","    - Eploratory Data Analysis\n","        * Understand what kind of data we are using (categorical, numerical)\n","        * `df.info()` `df.describe()` `df.shape()`\n","        * Missing values, `df.corr()`, work with concatenated dataset\n","        * Target distribution\n","        * Correlations between features\n","    - Feature Engineering\n","    - Model Building"],"metadata":{}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import StratifiedKFold"],"metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:48:33.803933Z","iopub.execute_input":"2021-06-27T10:48:33.804306Z","iopub.status.idle":"2021-06-27T10:48:35.103146Z","shell.execute_reply.started":"2021-06-27T10:48:33.804225Z","shell.execute_reply":"2021-06-27T10:48:35.10207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def concat_df(train_data, test_data):\n","    # Concatenates training and test sets\n","    # reset_index(drop=True) deletes original index, and replaces with 0,1,2...N\n","    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n","\n","def divide_df(all_data):\n","    # Returns divided dfs of training and test set\n","    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n","    \n","df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\n","df_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n","df_all = concat_df(df_train, df_test) # Good when dealing with missing values to overcome overfitting\n","\n","df_train.name = 'Training Set'\n","df_test.name = 'Test Set'\n","df_all.name = 'All Set'\n","\n","dfs = [df_train, df_test]\n","\n","print(f\"Training Set = {df_train.shape}\")\n","print(f\"Test Set = {df_test.shape}\\n\")\n","print(df_train.columns)\n","print(df_test.columns)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:48:35.104791Z","iopub.execute_input":"2021-06-27T10:48:35.105177Z","iopub.status.idle":"2021-06-27T10:48:35.152574Z","shell.execute_reply.started":"2021-06-27T10:48:35.105136Z","shell.execute_reply":"2021-06-27T10:48:35.151376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Eploratory Data Analysis\n","\n","### 1.1 Overview\n","* `PassengerId` is the unique id of the row and it doesn't have any effect on target\n","* `Survived` is the target variable we are trying to predict (**0** or **1**):\n","    - **1 = Survived**\n","    - **0 = Not Survived**\n","* `Pclass` (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has **3** unique values (**1**,  **2 **or **3**):\n","    - **1 = Upper Class**\n","    - **2 = Middle Class**\n","    - **3 = Lower Class**\n","* `Name`, `Sex` and `Age` are self-explanatory\n","* `SibSp` is the total number of the passengers' siblings and spouse\n","* `Parch` is the total number of the passengers' parents and children\n","* `Ticket` is the ticket number of the passenger\n","* `Fare` is the passenger fare\n","* `Cabin` is the cabin number of the passenger\n","* `Embarked` is port of embarkation and it is a categorical feature which has **3** unique values (**C**, **Q** or **S**):\n","    - **C = Cherbourg**\n","    - **Q = Queenstown**\n","    - **S = Southampton**"],"metadata":{}},{"cell_type":"code","source":["print(df_train.info())\n","df_train.head()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.724721Z","iopub.execute_input":"2021-06-26T06:38:36.725026Z","iopub.status.idle":"2021-06-26T06:38:36.767484Z","shell.execute_reply.started":"2021-06-26T06:38:36.724997Z","shell.execute_reply":"2021-06-26T06:38:36.766476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_test.info())\n","df_test.sample(3)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.768998Z","iopub.execute_input":"2021-06-26T06:38:36.769273Z","iopub.status.idle":"2021-06-26T06:38:36.80025Z","shell.execute_reply.started":"2021-06-26T06:38:36.769246Z","shell.execute_reply":"2021-06-26T06:38:36.799362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2 Missing Values\n","* Training set have missing values in Age, Cabin and Embarked columns.\n","* Test set have missing values in Age, Cabin and Fare columns.\n","* It is convenient to work on concatenated training and test set while dealing with missing values, otherwise filled data may overfit to training or test set samples."],"metadata":{}},{"cell_type":"code","source":["def display_missing(df):\n","    for col in df.columns.tolist():\n","        print(f'{col} column missing values: {df[col].isnull().sum()}')\n","    print('\\n')\n","\n","for df in dfs:\n","    print(f'{df.name}')\n","    display_missing(df)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.801867Z","iopub.execute_input":"2021-06-26T06:38:36.80228Z","iopub.status.idle":"2021-06-26T06:38:36.818786Z","shell.execute_reply.started":"2021-06-26T06:38:36.802234Z","shell.execute_reply":"2021-06-26T06:38:36.817762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all.corr().style.background_gradient(cmap='coolwarm').set_precision(3)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.820091Z","iopub.execute_input":"2021-06-26T06:38:36.820494Z","iopub.status.idle":"2021-06-26T06:38:36.883662Z","shell.execute_reply.started":"2021-06-26T06:38:36.820463Z","shell.execute_reply":"2021-06-26T06:38:36.88263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.2.1 Age\n","Replace with median age, but not median age of the whole dataset.\n","\n","But with the medians of Sex and Pclass groups"],"metadata":{}},{"cell_type":"code","source":["df_all_corr = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n","df_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n","df_all_corr[df_all_corr['Feature 1'] == 'Age'] # Check with Pclass too"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.885266Z","iopub.execute_input":"2021-06-26T06:38:36.885697Z","iopub.status.idle":"2021-06-26T06:38:36.910718Z","shell.execute_reply.started":"2021-06-26T06:38:36.885654Z","shell.execute_reply":"2021-06-26T06:38:36.909889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n","print(age_by_pclass_sex, '\\n')\n","\n","for pclass in range(1, 4):\n","    for sex in ['female', 'male']:\n","        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n","print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n","\n","# Filling the missing values in Age with the medians of Sex and Pclass groups\n","df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.913017Z","iopub.execute_input":"2021-06-26T06:38:36.913283Z","iopub.status.idle":"2021-06-26T06:38:36.946338Z","shell.execute_reply.started":"2021-06-26T06:38:36.913257Z","shell.execute_reply":"2021-06-26T06:38:36.945422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.2.2 Embarked\n","2 missing values, let's see them. Both female, 1st class, same ticket number. That means they knew each other. \n","\n","Let's check the mode for female upper class embarked. \n","\n","Sometimes googling will also help."],"metadata":{}},{"cell_type":"code","source":["df_all[df_all['Embarked'].isnull()]"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.94914Z","iopub.execute_input":"2021-06-26T06:38:36.949558Z","iopub.status.idle":"2021-06-26T06:38:36.968311Z","shell.execute_reply.started":"2021-06-26T06:38:36.949524Z","shell.execute_reply":"2021-06-26T06:38:36.967117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all.groupby(['Sex', 'Pclass']).agg(lambda x:x.value_counts().index[0])['Embarked'] # Only female upper class embarked = S"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:36.97005Z","iopub.execute_input":"2021-06-26T06:38:36.970592Z","iopub.status.idle":"2021-06-26T06:38:37.020628Z","shell.execute_reply.started":"2021-06-26T06:38:36.970559Z","shell.execute_reply":"2021-06-26T06:38:37.01961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all['Embarked'].mode() # All people = S"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.02174Z","iopub.execute_input":"2021-06-26T06:38:37.022017Z","iopub.status.idle":"2021-06-26T06:38:37.03108Z","shell.execute_reply.started":"2021-06-26T06:38:37.02199Z","shell.execute_reply":"2021-06-26T06:38:37.029934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all.groupby(['Embarked']).agg(lambda x:x.value_counts().index[0])['Pclass'] # Only upper class both male / female = C"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.032299Z","iopub.execute_input":"2021-06-26T06:38:37.032611Z","iopub.status.idle":"2021-06-26T06:38:37.088953Z","shell.execute_reply.started":"2021-06-26T06:38:37.03257Z","shell.execute_reply":"2021-06-26T06:38:37.087782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Filling the missing values in Embarked with S\n","df_all['Embarked'] = df_all['Embarked'].fillna('S')"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.090949Z","iopub.execute_input":"2021-06-26T06:38:37.091421Z","iopub.status.idle":"2021-06-26T06:38:37.097581Z","shell.execute_reply.started":"2021-06-26T06:38:37.091374Z","shell.execute_reply":"2021-06-26T06:38:37.096659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.2.3 Fare\n","\n","There is only one passenger with missing Fare value. We can assume that Fare is related to family size (Parch and SibSp) and Pclass features. Median Fare value of a male with a third class ticket and no family is a logical choice to fill the missing value."],"metadata":{}},{"cell_type":"code","source":["df_all[df_all['Fare'].isnull()] # Looking at the null value"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.099152Z","iopub.execute_input":"2021-06-26T06:38:37.099631Z","iopub.status.idle":"2021-06-26T06:38:37.121219Z","shell.execute_reply.started":"2021-06-26T06:38:37.099567Z","shell.execute_reply":"2021-06-26T06:38:37.120522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()[3][0][0]\n","print(med_fare)\n","\n","# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\n","df_all['Fare'] = df_all['Fare'].fillna(med_fare)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.122125Z","iopub.execute_input":"2021-06-26T06:38:37.122404Z","iopub.status.idle":"2021-06-26T06:38:37.139935Z","shell.execute_reply.started":"2021-06-26T06:38:37.122376Z","shell.execute_reply":"2021-06-26T06:38:37.139026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.2.4 Cabin\n","\n","* On the Boat Deck there were 6 rooms labeled as T, U, W, X, Y, Z but only the T cabin is present in the dataset\n","* A, B and C decks were only for 1st class passengers\n","* D and E decks were for all classes\n","* F and G decks were for both 2nd and 3rd class passengers\n","* From going A to G, distance to the staircase increases which might be a factor of survival"],"metadata":{}},{"cell_type":"code","source":["df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.141063Z","iopub.execute_input":"2021-06-26T06:38:37.141366Z","iopub.status.idle":"2021-06-26T06:38:37.151045Z","shell.execute_reply.started":"2021-06-26T06:38:37.14132Z","shell.execute_reply":"2021-06-26T06:38:37.15031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all.groupby(['Deck', 'Pclass']).count() # As you see we have A,B,C,D,E,F,G,T,M"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.15209Z","iopub.execute_input":"2021-06-26T06:38:37.152374Z","iopub.status.idle":"2021-06-26T06:38:37.18105Z","shell.execute_reply.started":"2021-06-26T06:38:37.152346Z","shell.execute_reply":"2021-06-26T06:38:37.180319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all_decks = df_all.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch','Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n","df_all_decks"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.182077Z","iopub.execute_input":"2021-06-26T06:38:37.18237Z","iopub.status.idle":"2021-06-26T06:38:37.208419Z","shell.execute_reply.started":"2021-06-26T06:38:37.182334Z","shell.execute_reply":"2021-06-26T06:38:37.207401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_pclass_dist(df):\n","    \n","    # Creating a dictionary for every passenger class count in every deck\n","    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n","    decks = df.columns.levels[0] # Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T'], dtype='object', name='Deck')\n","    \n","    for deck in decks:\n","        for pclass in range(1, 4):\n","            try:\n","                count = df[deck][pclass][0]\n","                deck_counts[deck][pclass] = count \n","            except KeyError:\n","                deck_counts[deck][pclass] = 0\n","                \n","    df_decks = pd.DataFrame(deck_counts)    \n","    deck_percentages = {}\n","\n","    # Creating a dictionary for every passenger class percentage in every deck\n","    for col in df_decks.columns:\n","        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n","        \n","    return deck_counts, deck_percentages\n","\n","def display_pclass_dist(percentages):\n","    \n","    df_percentages = pd.DataFrame(percentages).transpose()\n","    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n","    bar_count = np.arange(len(deck_names))  \n","    bar_width = 0.85\n","    \n","    pclass1 = df_percentages[0]\n","    pclass2 = df_percentages[1]\n","    pclass3 = df_percentages[2]\n","    \n","    plt.figure(figsize=(20, 10))\n","    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n","    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n","    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n","\n","    plt.xlabel('Deck', size=15, labelpad=20)\n","    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n","    plt.xticks(bar_count, deck_names)    \n","    plt.tick_params(axis='x', labelsize=15)\n","    plt.tick_params(axis='y', labelsize=15)\n","    \n","    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n","    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n","    \n","    plt.show()    \n","\n","all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\n","display_pclass_dist(all_deck_per)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.209575Z","iopub.execute_input":"2021-06-26T06:38:37.209844Z","iopub.status.idle":"2021-06-26T06:38:37.587354Z","shell.execute_reply.started":"2021-06-26T06:38:37.209816Z","shell.execute_reply":"2021-06-26T06:38:37.586366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Passenger in the T deck is changed to A\n","idx = df_all[df_all['Deck'] == 'T'].index\n","df_all.loc[idx, 'Deck'] = 'A'\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.588883Z","iopub.execute_input":"2021-06-26T06:38:37.589328Z","iopub.status.idle":"2021-06-26T06:38:37.597575Z","shell.execute_reply.started":"2021-06-26T06:38:37.589257Z","shell.execute_reply":"2021-06-26T06:38:37.596432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all_decks_survived = df_all.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare', \n","                                                                                   'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name':'Count'}).transpose()\n","\n","def get_survived_dist(df):\n","    \n","    # Creating a dictionary for every survival count in every deck\n","    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n","    decks = df.columns.levels[0]    \n","\n","    for deck in decks:\n","        for survive in range(0, 2):\n","            surv_counts[deck][survive] = df[deck][survive][0]\n","            \n","    df_surv = pd.DataFrame(surv_counts)\n","    surv_percentages = {}\n","\n","    for col in df_surv.columns:\n","        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]\n","        \n","    return surv_counts, surv_percentages\n","\n","def display_surv_dist(percentages):\n","    \n","    df_survived_percentages = pd.DataFrame(percentages).transpose()\n","    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n","    bar_count = np.arange(len(deck_names))  \n","    bar_width = 0.85    \n","\n","    not_survived = df_survived_percentages[0]\n","    survived = df_survived_percentages[1]\n","    \n","    plt.figure(figsize=(20, 10))\n","    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n","    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n"," \n","    plt.xlabel('Deck', size=15, labelpad=20)\n","    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n","    plt.xticks(bar_count, deck_names)    \n","    plt.tick_params(axis='x', labelsize=15)\n","    plt.tick_params(axis='y', labelsize=15)\n","    \n","    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n","    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n","    \n","    plt.show()\n","\n","all_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\n","display_surv_dist(all_surv_per)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:37.599554Z","iopub.execute_input":"2021-06-26T06:38:37.600047Z","iopub.status.idle":"2021-06-26T06:38:38.032636Z","shell.execute_reply.started":"2021-06-26T06:38:37.599997Z","shell.execute_reply":"2021-06-26T06:38:38.031393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all['Deck'].head()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.034399Z","iopub.execute_input":"2021-06-26T06:38:38.034818Z","iopub.status.idle":"2021-06-26T06:38:38.04319Z","shell.execute_reply.started":"2021-06-26T06:38:38.034774Z","shell.execute_reply":"2021-06-26T06:38:38.041998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\n","df_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\n","df_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n","\n","df_all['Deck'].value_counts()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.048412Z","iopub.execute_input":"2021-06-26T06:38:38.048844Z","iopub.status.idle":"2021-06-26T06:38:38.067623Z","shell.execute_reply.started":"2021-06-26T06:38:38.048793Z","shell.execute_reply":"2021-06-26T06:38:38.066479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dropping the Cabin feature\n","df_all.drop(['Cabin'], inplace=True, axis=1)\n","\n","df_train, df_test = divide_df(df_all)\n","dfs = [df_train, df_test]\n","\n","for df in dfs:\n","    display_missing(df)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.069715Z","iopub.execute_input":"2021-06-26T06:38:38.07031Z","iopub.status.idle":"2021-06-26T06:38:38.093481Z","shell.execute_reply.started":"2021-06-26T06:38:38.070176Z","shell.execute_reply":"2021-06-26T06:38:38.092249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.3 Target Distribution\n","\n","* 38.38% (342/891) of training set is Class 1\n","* 61.62% (549/891) of training set is Class 0"],"metadata":{}},{"cell_type":"code","source":["df_train['Survived'].value_counts() "],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.094981Z","iopub.execute_input":"2021-06-26T06:38:38.095305Z","iopub.status.idle":"2021-06-26T06:38:38.105424Z","shell.execute_reply.started":"2021-06-26T06:38:38.095256Z","shell.execute_reply":"2021-06-26T06:38:38.104415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["survived = df_train['Survived'].value_counts()[1]\n","not_survived = df_train['Survived'].value_counts()[0]\n","survived_per = survived / df_train.shape[0] * 100\n","not_survived_per = not_survived / df_train.shape[0] * 100\n","\n","print(f'{survived} of {df_train.shape[0]} passengers survived and it is the {survived_per:.2f}% of the training set.')\n","print(f'{not_survived} of {df_train.shape[0]} passengers didnt survive and it is the {not_survived_per:.2f}% of the training set.')\n","\n","df_train['Survived'].value_counts().plot(kind='bar')\n","plt.xlabel('Survival', size=15, labelpad=15)\n","plt.ylabel('Passenger Count', size=15, labelpad=15)\n","plt.xticks((0, 1), [f'Not Survived ({not_survived_per:.2f}%)', f'Survived ({survived_per:.2f}%)'], rotation=0)\n","plt.title('Training Set Survival Distribution', size=15, y=1.05)\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.106732Z","iopub.execute_input":"2021-06-26T06:38:38.107036Z","iopub.status.idle":"2021-06-26T06:38:38.28425Z","shell.execute_reply.started":"2021-06-26T06:38:38.107007Z","shell.execute_reply":"2021-06-26T06:38:38.283105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.4 Correlations"],"metadata":{}},{"cell_type":"code","source":["df_train_corr = df_train.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n","df_train_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n","df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True) # deletes all odd rows\n","df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index) # deletes similar aga-age, parch-parch\n","\n","df_test_corr = df_test.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n","df_test_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n","df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\n","df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr['Correlation Coefficient'] == 1.0].index)\n","\n","df_train_corr.reset_index()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:40:42.376384Z","iopub.execute_input":"2021-06-26T06:40:42.376741Z","iopub.status.idle":"2021-06-26T06:40:42.41153Z","shell.execute_reply.started":"2021-06-26T06:40:42.376711Z","shell.execute_reply":"2021-06-26T06:40:42.410766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_corr.reset_index()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:40:52.726863Z","iopub.execute_input":"2021-06-26T06:40:52.727417Z","iopub.status.idle":"2021-06-26T06:40:52.741938Z","shell.execute_reply.started":"2021-06-26T06:40:52.727359Z","shell.execute_reply":"2021-06-26T06:40:52.740938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training set high correlations\n","corr = df_train_corr_nd['Correlation Coefficient'] > 0.1\n","df_train_corr_nd[corr].reset_index()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.325936Z","iopub.execute_input":"2021-06-26T06:38:38.326194Z","iopub.status.idle":"2021-06-26T06:38:38.35234Z","shell.execute_reply.started":"2021-06-26T06:38:38.326165Z","shell.execute_reply":"2021-06-26T06:38:38.35109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test set high correlations\n","corr = df_test_corr_nd['Correlation Coefficient'] > 0.1\n","df_test_corr_nd[corr].reset_index()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.353916Z","iopub.execute_input":"2021-06-26T06:38:38.354321Z","iopub.status.idle":"2021-06-26T06:38:38.374397Z","shell.execute_reply.started":"2021-06-26T06:38:38.354255Z","shell.execute_reply":"2021-06-26T06:38:38.37275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.5 Target Distribution in Features\n","\n","Continious and categorical features"],"metadata":{}},{"cell_type":"code","source":["cat_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n","\n","fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\n","plt.subplots_adjust(right=1.5, top=1.25)\n","\n","for i, feature in enumerate(cat_features, 1):    \n","    plt.subplot(2, 3, i)\n","    sns.countplot(x=feature, hue='Survived', data=df_train)\n","    \n","    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n","    plt.ylabel('Passenger Count', size=20, labelpad=15)    \n","    plt.tick_params(axis='x', labelsize=20)\n","    plt.tick_params(axis='y', labelsize=20)\n","    \n","    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 18})\n","    plt.title('Count of Survival in {} Feature'.format(feature), size=20, y=1.05)\n","\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:38.376341Z","iopub.execute_input":"2021-06-26T06:38:38.376754Z","iopub.status.idle":"2021-06-26T06:38:39.707901Z","shell.execute_reply.started":"2021-06-26T06:38:38.376696Z","shell.execute_reply":"2021-06-26T06:38:39.707096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.6 Conclusion\n","\n","Most of the features are correlated with each other. This relationship can be used to create new features with feature transformation and feature interaction."],"metadata":{}},{"cell_type":"code","source":["df_all = concat_df(df_train, df_test)\n","df_all.head()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-26T06:38:39.708963Z","iopub.execute_input":"2021-06-26T06:38:39.709495Z","iopub.status.idle":"2021-06-26T06:38:39.736401Z","shell.execute_reply.started":"2021-06-26T06:38:39.709456Z","shell.execute_reply":"2021-06-26T06:38:39.735444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Feature Engineering"],"metadata":{}},{"cell_type":"markdown","source":[],"metadata":{}},{"cell_type":"code","source":[],"metadata":{},"execution_count":null,"outputs":[]}]}